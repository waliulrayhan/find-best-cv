
================================================================================
OVERFITTING ANALYSIS REPORT
================================================================================

1. TRAINING-VALIDATION GAP ANALYSIS
   --------------------------------
   Final Training Accuracy:    0.9051
   Final Validation Accuracy:  0.8145
   Accuracy Gap:              0.0905 (9.05%)
   
   Final Training Loss:        0.3029
   Final Validation Loss:      2.2445
   Loss Gap:                  1.9417
   
   Assessment: ✓ NO OVERFITTING
   Reasoning: Accuracy gap is 9.05%, which is within 
              the acceptable threshold of 10%.

2. GENERALIZATION PERFORMANCE
   ---------------------------
   Validation Accuracy:        0.8145
   Test Accuracy:             0.8418
   Val-Test Gap:              0.0273
   
   Assessment: ✓ GOOD GENERALIZATION
   Reasoning: The model performs similarly
              on unseen test data compared to validation data.

3. LEARNING CURVE BEHAVIOR
   ------------------------
   Validation F1 Trend (last 5 epochs): -0.000190
   Validation Loss Trend: Increasing
   
   Assessment: ✓ STABLE LEARNING
   Reasoning: The validation metrics show stable
              behavior without sudden degradation.

4. FINAL VERDICT
   -------------
   Overfitting Risk: MODERATE ⚠
   
   Evidence Supporting No Overfitting:
   • Train-Val accuracy gap is only 9.05% (< 10% threshold)
   • Validation metrics remain stable in final epochs
   • Test performance (0.8418) confirms good generalization
   • Loss curves converge without divergence
   
   Recommended Actions:
   • Current model configuration is well-balanced
   • Model is ready for deployment
   • Continue monitoring performance on new data

5. MODEL ROBUSTNESS INDICATORS
   ----------------------------
   Per-class F1 scores:
   • Mean:     0.7704
   • Std Dev:  0.2677
   • Min:      0.0000
   • Max:      0.9730
   
   Assessment: ⚠ VARIABLE PERFORMANCE
   across different classes indicates moderate model robustness.

================================================================================
CONCLUSION: The model demonstrates strong generalization capabilities
with minimal signs of overfitting. The training process appears well-regularized.
================================================================================

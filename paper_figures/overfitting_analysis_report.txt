
================================================================================
OVERFITTING ANALYSIS REPORT
================================================================================

1. TRAINING-VALIDATION GAP ANALYSIS
   --------------------------------
   Final Training Accuracy:    0.8867
   Final Validation Accuracy:  0.8065
   Accuracy Gap:              0.0802 (8.02%)
   
   Final Training Loss:        0.4449
   Final Validation Loss:      1.1653
   Loss Gap:                  0.7203
   
   Assessment: ✓ NO OVERFITTING
   Reasoning: Accuracy gap is 8.02%, which is within 
              the acceptable threshold of 10%.

2. GENERALIZATION PERFORMANCE
   ---------------------------
   Validation Accuracy:        0.8065
   Test Accuracy:             0.8525
   Val-Test Gap:              0.0461
   
   Assessment: ✓ GOOD GENERALIZATION
   Reasoning: The model performs similarly
              on unseen test data compared to validation data.

3. LEARNING CURVE BEHAVIOR
   ------------------------
   Validation F1 Trend (last 5 epochs): -0.001233
   Validation Loss Trend: Stable/Improving
   
   Assessment: ✓ STABLE LEARNING
   Reasoning: The validation metrics show stable
              behavior without sudden degradation.

4. FINAL VERDICT
   -------------
   Overfitting Risk: LOW ✓
   
   Evidence Supporting No Overfitting:
   • Train-Val accuracy gap is only 8.02% (< 10% threshold)
   • Validation metrics remain stable in final epochs
   • Test performance (0.8525) confirms good generalization
   • Loss curves converge without divergence
   
   Recommended Actions:
   • Current model configuration is well-balanced
   • Model is ready for deployment
   • Continue monitoring performance on new data

5. MODEL ROBUSTNESS INDICATORS
   ----------------------------
   Per-class F1 scores:
   • Mean:     0.7798
   • Std Dev:  0.2714
   • Min:      0.0000
   • Max:      1.0000
   
   Assessment: ⚠ VARIABLE PERFORMANCE
   across different classes indicates moderate model robustness.

================================================================================
CONCLUSION: The model demonstrates strong generalization capabilities
with minimal signs of overfitting. The training process appears well-regularized.
================================================================================
